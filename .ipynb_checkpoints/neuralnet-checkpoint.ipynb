{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural\n",
    "Nesta tarefa você deve implementar uma rede neural com duas camadas totalmente conectadas. O treinamento e a validação deverão ser executados no CIFAR-10. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração inicial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rncvc.classifiers.neural_net import NeuralNet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Permite a recarga automática de arquivos python importados\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" retorna erro relativo \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente a rede neural na classe `NeuralNet` no arquivo `rncvc/classifiers/neural_net.py`. Os parâmetros (pesos) da rede são armazenados na variável (dicionário) `self.params`, onde as chaves são os nomes (string) das camadas e os valores são numpy arrays com os pesos. A seguir, inicializamos dados sintéticos e uma rede simplificada para guiar o procedimento de desenvolvimento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um modelo e um conjunto de dados para alguns testes.\n",
    "# Definimos um seed para que seja possivel a conferência dos resultados.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return NeuralNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward: calcule valores de predição para as classes\n",
    "A função `NeuralNet.loss` utiliza os dados e os parâmetros para calcular as predições para cada classe. Além disso, são calculados: o valor da função de custo e os gradientes dos parâmetros. \n",
    "\n",
    "Implemente a primeira parte, que faz a predição das classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suas predicoes:\n",
      "None\n",
      "\n",
      "Predicoes corretas:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Diferenca entre sua implementacao e os valores corretos:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c67cf06469a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# A diferenca deve ser pequena. Normalmente < 1e-7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Diferenca entre sua implementacao e os valores corretos:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcorrect_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X, reg=0.1)\n",
    "print 'Suas predicoes:'\n",
    "print scores\n",
    "print\n",
    "print 'Predicoes corretas:'\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print correct_scores\n",
    "print\n",
    "\n",
    "# A diferenca deve ser pequena. Normalmente < 1e-7\n",
    "print 'Diferenca entre sua implementacao e os valores corretos:'\n",
    "print np.sum(np.abs(scores - correct_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward: calcule a função de custo\n",
    "\n",
    "Na mesma função, implemente a segunda parte, calculando os valores da função de custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferença da sua funcao de custo e do custo correto:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5f56ffcdd9b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# deve ser pequena a diferenca, normalmente < 1e-12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Diferença da sua funcao de custo e do custo correto:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcorrect_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# deve ser pequena a diferenca, normalmente < 1e-12\n",
    "print 'Diferença da sua funcao de custo e do custo correto:'\n",
    "print np.sum(np.abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward\n",
    "\n",
    "Implemente o restante da função. Aqui os gradientes com respeito às variáveis `W1`, `b1`, `W2`, e `b2` devem ser calculados. \n",
    "Com uma implementação correta de todo o processo de backward você deve ser capaz de conferir utilizando o gradiente numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rncvc.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use o gradiente numérico para verificar sua implementação da etapa backward.\n",
    "# Se sua implementação estiver correta, a diferença entre os gradientes será \n",
    "# inferior a 1e-8 para cada um das camadas de pesos: W1, W2, b1, b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# as diferenças devem ser pequenas (<1e-8)\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print '%s erro relativo max: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a rede (modelo toy)\n",
    "\n",
    "Para treinar, utilize o SGD. Preencha os espaços em branco da função NeuralNet.train. Ainda, você precisa implementar a função NeuralNet.predict utilizada para verificar acurácia durante o treinamento. \n",
    "\n",
    "Com a implementação completa, executando o código abaixo, você deve ser capaz de obter o valor da função de custo próximo a 0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e11c2614a106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m stats = net.train(X, y, X, y,\n\u001b[0;32m      3\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             num_iters=100, verbose=False)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Loss de treinamento: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_history'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\GitHub\\CNN\\rncvc\\classifiers\\neural_net.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, X_val, y_val, learning_rate, learning_rate_decay, reg, num_iters, batch_size, verbose)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[1;31m# Calcule a funcao de custo e os gradientes usando o minibatch atual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m       \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\GitHub\\CNN\\rncvc\\classifiers\\neural_net.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, reg)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# Calcula a etapa forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=0.1,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print 'Loss de treinamento: ', stats['loss_history'][-1]\n",
    "\n",
    "# plotagem dos valores de custo durante o treinamento\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o CIFAR-10\n",
    "Com sua implementação completa (e correta), podemos carregar os dados do CIFAR-10 e usá-los para treinar um modelo de rede neuralem dados reais.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name imread",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-49eff184c139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrncvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_CIFAR10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_CIFAR10_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mCarregando\u001b[0m \u001b[0mo\u001b[0m \u001b[0mCIFAR\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m \u001b[0me\u001b[0m \u001b[0mefetuando\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;31mé\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprocessamento\u001b[0m \u001b[0mpara\u001b[0m \u001b[0mpreparar\u001b[0m \u001b[0mos\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\GitHub\\CNN\\rncvc\\data_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_CIFAR_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name imread"
     ]
    }
   ],
   "source": [
    "from rncvc.data_utils import load_CIFAR10, save_model, load_model\n",
    "\n",
    "def get_CIFAR10_data():\n",
    "    \"\"\"\n",
    "    Carregando o CIFAR-10 e efetuando pré-processamento para preparar os dados\n",
    "    para entrada na Rede Neural.     \n",
    "    \"\"\"\n",
    "    # Carrega o CIFAR-10\n",
    "    cifar10_dir = 'rncvc/datasets/cifar-10-batches-py'    \n",
    "    X_train, y_train, X_valid, y_valid = load_CIFAR10(cifar10_dir)   \n",
    "\n",
    "    # Normalizacao dos dados: subtracao da imagem media\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_valid -= mean_image\n",
    "    \n",
    "    print X_train.shape\n",
    "    print X_valid.shape\n",
    "    \n",
    "    # Imagens para linhas \n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], -1)    \n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# Utiliza a funcao acima pra carregar os dados.\n",
    "X_train, y_train, X_valid, y_valid = get_CIFAR10_data()\n",
    "print 'Shape dados treinamento: ', X_train.shape\n",
    "print 'Shape das classes (treinamento): ', y_train.shape\n",
    "print 'Shape dados validacao: ', X_valid.shape\n",
    "print 'Shape das classes (validacao): ', y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a Rede no CIFAR-10\n",
    "Para treinar a rede use SGD com momentum. Salve o melhor modelo com a função data_utils.save_model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Treina a rede\n",
    "stats = net.train(X_train, y_train, X_valid, y_valid,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.5, verbose=True)\n",
    "\n",
    "# Efetua predicao no conjunto de validacao\n",
    "val_acc = (net.predict(X_valid) == y_valid).mean()\n",
    "print 'Acuracia de validacao: ', val_acc\n",
    "\n",
    "# Salva o modelo da rede treinada\n",
    "model_path = 'model.pickle'\n",
    "save_model(model_path, net.params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acompanhando o treinamento\n",
    "\n",
    "Com os hiperparâmetros definidos anteriormente você provavelmente não obterá bons resultados: a acurácia não deve passar de 30%. \n",
    "\n",
    "Uma estratégia para entender o que não está bom durante o treinamento é plotar os valores da função de custo e acurácia durante o treinamento. \n",
    "\n",
    "Outra estratégia é visualizar os pesos aprendidos na primeira camada durante o processo de otimização. Normalmente, redes treinadas em dados visuais apresentam padrões estruturais visíveis na primeira camada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c610fe47d38c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plota a função de custo e acurácia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_history'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAADpCAYAAAATWPImAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbAEADCS2AAAGElsAAAOJLQCAgf4PfOu5jC1SQpAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8ceecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plota a função de custo e acurácia\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 40 into shape (32,32,3,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-47b6df255693>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mshow_net_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-47b6df255693>\u001b[0m in \u001b[0;36mshow_net_weights\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_net_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisualize_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 40 into shape (32,32,3,newaxis)"
     ]
    }
   ],
   "source": [
    "from rncvc.vis_utils import visualize_grid\n",
    "\n",
    "# Visualiza os pesos da rede\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio RNCVC 2017\n",
    "\n",
    "**Dicas**\n",
    "* Tune os hiperparâmetros (taxa de aprendizado, número de neurônios, etc). \n",
    "* Regularize o modelo: teste o uso de Regularização L2 e Dropout. \n",
    "* Use validação cruzada para achar os melhores hiperparâmetros.\n",
    "* Utilize um esquema mais sofisticado de atualização dos pesos (ex: SGD + Momentum, Nesterov, Adadelta, Adam, RMSProp).\n",
    "* Teste funções de ativação (ex: ELU, Leaky ReLU) e Batch Normalization. \n",
    "* Salve o melhor modelo obtido usando data_utils.save_model() e data_utils.load_model() para abrir.\n",
    "* O campeão do ano passado conseguiu 62% de acurácia! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o desafio: é <b>fundamental</b> que o trecho abaixo seja executado sem problemas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'passe_seus_parametros_aqui' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b4566cdccd9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Assuma que o modelo são os pesos serializados em disco usando data_utils.save_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpasse_seus_parametros_aqui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'path/to/best/model.pickle'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'passe_seus_parametros_aqui' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuma que o modelo são os pesos serializados em disco usando data_utils.save_model()\n",
    "\n",
    "net = NeuralNet(passe_seus_parametros_aqui)\n",
    "\n",
    "best_model = 'path/to/best/model.pickle'\n",
    "model = load_model(best_model)\n",
    "net.params = model\n",
    "\n",
    "# Retorna um vetor de predição (N x 1), onde N é o número de instâncias\n",
    "# As classes retornadas aqui devem ser inteiros: [0, 1, 2, ..., C]\n",
    "# Assuma que X_teste e uma matriz de instancias (N_test, D) \n",
    "# Voce nao tera o X_teste oficial, use outro conjunto para validar.\n",
    "predicted_classes = net.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporte abaixo os valores de acurácia no treino e validação do modelo enviado para o desafio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treino: 00.00%\n",
    "# Validacao: 00.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
