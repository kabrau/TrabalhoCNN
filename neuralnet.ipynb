{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural\n",
    "Nesta tarefa você deve implementar uma rede neural com duas camadas totalmente conectadas. O treinamento e a validação deverão ser executados no CIFAR-10. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração inicial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rncvc.classifiers.neural_net import NeuralNet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Permite a recarga automática de arquivos python importados\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" retorna erro relativo \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente a rede neural na classe `NeuralNet` no arquivo `rncvc/classifiers/neural_net.py`. Os parâmetros (pesos) da rede são armazenados na variável (dicionário) `self.params`, onde as chaves são os nomes (string) das camadas e os valores são numpy arrays com os pesos. A seguir, inicializamos dados sintéticos e uma rede simplificada para guiar o procedimento de desenvolvimento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um modelo e um conjunto de dados para alguns testes.\n",
    "# Definimos um seed para que seja possivel a conferência dos resultados.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return NeuralNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward: calcule valores de predição para as classes\n",
    "A função `NeuralNet.loss` utiliza os dados e os parâmetros para calcular as predições para cada classe. Além disso, são calculados: o valor da função de custo e os gradientes dos parâmetros. \n",
    "\n",
    "Implemente a primeira parte, que faz a predição das classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suas predicoes:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Predicoes corretas:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Diferenca entre sua implementacao e os valores corretos:\n",
      "3.68027204961e-08\n"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X, reg=0.1)\n",
    "print 'Suas predicoes:'\n",
    "print scores\n",
    "print\n",
    "print 'Predicoes corretas:'\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print correct_scores\n",
    "print\n",
    "\n",
    "# A diferenca deve ser pequena. Normalmente < 1e-7\n",
    "print 'Diferenca entre sua implementacao e os valores corretos:'\n",
    "print np.sum(np.abs(scores - correct_scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward: calcule a função de custo\n",
    "\n",
    "Na mesma função, implemente a segunda parte, calculando os valores da função de custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferença da sua funcao de custo e do custo correto:\n",
      "1.79412040779e-13\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# deve ser pequena a diferenca, normalmente < 1e-12\n",
    "print 'Diferença da sua funcao de custo e do custo correto:'\n",
    "print np.sum(np.abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward\n",
    "\n",
    "Implemente o restante da função. Aqui os gradientes com respeito às variáveis `W1`, `b1`, `W2`, e `b2` devem ser calculados. \n",
    "Com uma implementação correta de todo o processo de backward você deve ser capaz de conferir utilizando o gradiente numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 erro relativo max: 3.669858e-09\n",
      "W2 erro relativo max: 3.440708e-09\n",
      "b2 erro relativo max: 3.865028e-11\n",
      "b1 erro relativo max: 2.738422e-09\n"
     ]
    }
   ],
   "source": [
    "from rncvc.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use o gradiente numérico para verificar sua implementação da etapa backward.\n",
    "# Se sua implementação estiver correta, a diferença entre os gradientes será \n",
    "# inferior a 1e-8 para cada um das camadas de pesos: W1, W2, b1, b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# as diferenças devem ser pequenas (<1e-8)\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print '%s erro relativo max: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a rede (modelo toy)\n",
    "\n",
    "Para treinar, utilize o SGD. Preencha os espaços em branco da função NeuralNet.train. Ainda, você precisa implementar a função NeuralNet.predict utilizada para verificar acurácia durante o treinamento. \n",
    "\n",
    "Com a implementação completa, executando o código abaixo, você deve ser capaz de obter o valor da função de custo próximo a 0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=0.1,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print 'Loss de treinamento: ', stats['loss_history'][-1]\n",
    "\n",
    "# plotagem dos valores de custo durante o treinamento\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o CIFAR-10\n",
    "Com sua implementação completa (e correta), podemos carregar os dados do CIFAR-10 e usá-los para treinar um modelo de rede neuralem dados reais.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rncvc.data_utils import load_CIFAR10, save_model, load_model\n",
    "\n",
    "def get_CIFAR10_data():\n",
    "    \"\"\"\n",
    "    Carregando o CIFAR-10 e efetuando pré-processamento para preparar os dados\n",
    "    para entrada na Rede Neural.     \n",
    "    \"\"\"\n",
    "    # Carrega o CIFAR-10\n",
    "    cifar10_dir = 'rncvc/datasets/cifar-10-batches-py'    \n",
    "    X_train, y_train, X_valid, y_valid = load_CIFAR10(cifar10_dir)   \n",
    "\n",
    "    # Normalizacao dos dados: subtracao da imagem media\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_valid -= mean_image\n",
    "    \n",
    "    print X_train.shape\n",
    "    print X_valid.shape\n",
    "    \n",
    "    # Imagens para linhas \n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], -1)    \n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# Utiliza a funcao acima pra carregar os dados.\n",
    "X_train, y_train, X_valid, y_valid = get_CIFAR10_data()\n",
    "print 'Shape dados treinamento: ', X_train.shape\n",
    "print 'Shape das classes (treinamento): ', y_train.shape\n",
    "print 'Shape dados validacao: ', X_valid.shape\n",
    "print 'Shape das classes (validacao): ', y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a Rede no CIFAR-10\n",
    "Para treinar a rede use SGD com momentum. Salve o melhor modelo com a função data_utils.save_model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 144\n",
    "num_classes = 10\n",
    "net = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "\n",
    "# Treina a rede\n",
    "stats = net.train(X_train, y_train, X_valid, y_valid,\n",
    "            num_iters=40000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.5, verbose=True)\n",
    "\n",
    "# Efetua predicao no conjunto de validacao\n",
    "val_acc = (net.predict(X_valid) == y_valid).mean()\n",
    "print 'Acuracia de validacao: ', val_acc\n",
    "\n",
    "# Salva o modelo da rede treinada\n",
    "model_path = 'model.pickle'\n",
    "save_model(model_path, net.params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acompanhando o treinamento\n",
    "\n",
    "Com os hiperparâmetros definidos anteriormente você provavelmente não obterá bons resultados: a acurácia não deve passar de 30%. \n",
    "\n",
    "Uma estratégia para entender o que não está bom durante o treinamento é plotar os valores da função de custo e acurácia durante o treinamento. \n",
    "\n",
    "Outra estratégia é visualizar os pesos aprendidos na primeira camada durante o processo de otimização. Normalmente, redes treinadas em dados visuais apresentam padrões estruturais visíveis na primeira camada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota a função de custo e acurácia\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rncvc.vis_utils import visualize_grid\n",
    "\n",
    "# Visualiza os pesos da rede\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio RNCVC 2017\n",
    "\n",
    "**Dicas**\n",
    "* Tune os hiperparâmetros (taxa de aprendizado, número de neurônios, etc). \n",
    "* Regularize o modelo: teste o uso de Regularização L2 e Dropout. \n",
    "* Use validação cruzada para achar os melhores hiperparâmetros.\n",
    "* Utilize um esquema mais sofisticado de atualização dos pesos (ex: SGD + Momentum, Nesterov, Adadelta, Adam, RMSProp).\n",
    "* Teste funções de ativação (ex: ELU, Leaky ReLU) e Batch Normalization. \n",
    "* Salve o melhor modelo obtido usando data_utils.save_model() e data_utils.load_model() para abrir.\n",
    "* O campeão do ano passado conseguiu 62% de acurácia! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o desafio: é <b>fundamental</b> que o trecho abaixo seja executado sem problemas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuma que o modelo são os pesos serializados em disco usando data_utils.save_model()\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "net = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Treina a rede\n",
    "stats = net.train(X_train, y_train, X_valid, y_valid,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.5, verbose=True)\n",
    "\n",
    "best_model = 'path/to/best/model.pickle'\n",
    "model = load_model(best_model)\n",
    "net.params = model\n",
    "\n",
    "# Retorna um vetor de predição (N x 1), onde N é o número de instâncias\n",
    "# As classes retornadas aqui devem ser inteiros: [0, 1, 2, ..., C]\n",
    "# Assuma que X_teste e uma matriz de instancias (N_test, D) \n",
    "# Voce nao tera o X_teste oficial, use outro conjunto para validar.\n",
    "predicted_classes = net.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporte abaixo os valores de acurácia no treino e validação do modelo enviado para o desafio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treino: 00.00%\n",
    "# Validacao: 00.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = [[-2.85, 0.86, 0.28]]\n",
    "\n",
    "N1 = 1\n",
    "Y = [1,0]\n",
    "reg = 0.5\n",
    "\n",
    "exp_scores2 = np.exp(scores1)\n",
    "norm =(exp_scores2 / np.sum(exp_scores2, axis=1, keepdims=True)) # [N x K]\n",
    "\n",
    "# compute softmax loss\n",
    "loss = -np.sum(np.log(norm[np.arange(N1), Y]))\n",
    "loss /= N\n",
    "#loss += 0.5 * reg * (np.sum(W1**2) + np.sum(W2**2))\n",
    "\n",
    "print norm, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
